import json
import shlex
import subprocess
import os
import uuid
from tkinter import ttk, messagebox
import tkinter as tk

import json
import subprocess
import os
import sys

from consts import TEMP_DIR

# ==========================================
# C·∫§U H√åNH
# ==========================================
FFMPEG_EXEC = "ffmpeg"
MAX_CLIPS_DIRECT = 10  # S·ªë clips t·ªëi ƒëa ƒë·ªÉ render tr·ª±c ti·∫øp, nhi·ªÅu h∆°n s·∫Ω d√πng file t·∫°m


def get_input_index(file_path, input_map, inputs_list):
    if file_path not in input_map:
        input_map[file_path] = len(inputs_list)
        inputs_list.append(file_path)
    return input_map[file_path]


def render_clip_to_temp(clip, clip_idx, width, height, fps, temp_dir):
    """
    Render m·ªôt clip ri√™ng l·∫ª ra file t·∫°m
    Returns: (temp_file_path, has_audio)
    """
    import tempfile
    
    temp_file = os.path.join(temp_dir, f"clip_{clip_idx:04d}.mp4")
    
    layers = clip.get('layers', [])
    main_video_layer = next((l for l in layers if l['type'] == 'video'), None)
    fill_color_layer = next((l for l in layers if l['type'] == 'fill-color'), None)
    
    input_map = {}
    inputs_list = []
    filter_chains = []
    
    transition_layers = []
    logo_layers = []
    
    for layer in layers:
        if layer == main_video_layer or layer == fill_color_layer:
            continue
        if layer['type'] == 'video':
            transition_layers.append(layer)
        elif layer['type'] == 'image-overlay':
            logo_layers.append(layer)
    
    has_audio = False
    current_v_pad = None
    
    # T·∫°o base layer
    if main_video_layer:
        path = main_video_layer['path']
        idx = get_input_index(path, input_map, inputs_list)
        cut_from = main_video_layer.get('cutFrom', 0)
        cut_to = main_video_layer.get('cutTo')
        
        trim_cmd = f"[{idx}:v]trim=start={cut_from}"
        if cut_to:
            trim_cmd += f":end={cut_to}"
        trim_cmd += f",setpts=PTS-STARTPTS[v_raw]"
        filter_chains.append(trim_cmd)
        
        has_audio = True
        atrim_cmd = f"[{idx}:a]atrim=start={cut_from}"
        if cut_to:
            atrim_cmd += f":end={cut_to}"
        atrim_cmd += f",asetpts=PTS-STARTPTS[a_out]"
        filter_chains.append(atrim_cmd)
        
        if main_video_layer.get('resizeMode') == 'contain-blur':
            bg_chain = (f"[v_raw]split=2[bg][fg];"
                        f"[bg]scale={width}:{height}:force_original_aspect_ratio=increase,crop={width}:{height},boxblur=20:10[bg_blur];"
                        f"[fg]scale={width}:{height}:force_original_aspect_ratio=decrease[fg_scaled];"
                        f"[bg_blur][fg_scaled]overlay=(W-w)/2:(H-h)/2[v_base]")
            filter_chains.append(bg_chain)
            current_v_pad = "[v_base]"
        else:
            scale_cmd = f"[v_raw]scale={width}:{height}:force_original_aspect_ratio=increase,crop={width}:{height}[v_base]"
            filter_chains.append(scale_cmd)
            current_v_pad = "[v_base]"
    
    elif fill_color_layer:
        color = fill_color_layer.get('color', '#000000')
        dur = clip.get('duration', 0.1)
        color_cmd = f"color=c={color}:s={width}x{height}:d={dur}[v_base]"
        filter_chains.append(color_cmd)
        current_v_pad = "[v_base]"
        
        silence_cmd = f"anullsrc=cl=stereo:r=44100:d={dur}[a_out]"
        filter_chains.append(silence_cmd)
        has_audio = True
    
    # Overlay logos
    for logo_idx, layer in enumerate(logo_layers):
        path = layer['path']
        idx = get_input_index(path, input_map, inputs_list)
        layer_pad = f"logo_{logo_idx}"
        
        # B·ªè loop filter, ch·ªâ scale logo PNG v·ªõi format t∆∞∆°ng th√≠ch
        cmd = f"[{idx}:v]scale={width}:{height}:force_original_aspect_ratio=decrease,format=yuva420p[{layer_pad}]"
        filter_chains.append(cmd)
        
        next_pad = f"v_logo_{logo_idx}"
        # B·ªè shortest=1, overlay t·ª± ƒë·ªông k√©o d√†i theo video base
        overlay_cmd = f"{current_v_pad}[{layer_pad}]overlay=(W-w)/2:(H-h)/2[{next_pad}]"
        filter_chains.append(overlay_cmd)
        current_v_pad = f"[{next_pad}]"
    
    # Overlay transitions
    for trans_idx, layer in enumerate(transition_layers):
        path = layer['path']
        idx = get_input_index(path, input_map, inputs_list)
        layer_pad = f"trans_{trans_idx}"
        
        cut_from = layer.get('cutFrom', 0)
        cut_to = layer.get('cutTo')
        start_time = layer.get('start', 0)
        stop_time = layer.get('stop')
        
        trim_part = f"[{idx}:v]trim=start={cut_from}"
        if cut_to:
            trim_part += f":end={cut_to}"
        trim_part += f",setpts=PTS-STARTPTS[{layer_pad}_raw]"
        filter_chains.append(trim_part)
        
        scale_trans = f"[{layer_pad}_raw]scale={width}:{height}[{layer_pad}]"
        filter_chains.append(scale_trans)
        
        fps_fix = f"[{layer_pad}]setpts=PTS+{start_time}/TB[{layer_pad}_shifted]"
        filter_chains.append(fps_fix)
        
        enable_expr = f"enable='between(t,{start_time},{stop_time})'"
        next_pad = f"v_trans_{trans_idx}"
        overlay_cmd = f"{current_v_pad}[{layer_pad}_shifted]overlay=0:0:{enable_expr}[{next_pad}]"
        filter_chains.append(overlay_cmd)
        current_v_pad = f"[{next_pad}]"
    
    # Finalize
    filter_chains.append(f"{current_v_pad}setsar=1,fps={fps}[v_out]")
    
    # Build command
    cmd_args = [FFMPEG_EXEC, "-y"]
    for inp in inputs_list:
        cmd_args.extend(["-i", inp])
    
    cmd_args.extend(["-filter_complex", ";".join(filter_chains)])
    cmd_args.extend(["-map", "[v_out]"])
    
    if has_audio:
        cmd_args.extend(["-map", "[a_out]"])
    
    cmd_args.extend([
        "-c:v", "h264_nvenc",
        "-preset", "p4",
        "-cq", "23",
        "-c:a", "aac",
        "-b:a", "192k",
        temp_file
    ])
    
    print(f"  Rendering clip {clip_idx + 1}...")
    subprocess.run(cmd_args, check=True, capture_output=True)
    
    return temp_file, has_audio


def generate_ffmpeg_command(config_path):
    with open(config_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
    width = json_data.get('width', 1920)
    height = json_data.get('height', 1080)
    fps = json_data.get('fps', 25)
    out_path = json_data.get('outPath', 'output.mp4')
    
    num_clips = len(json_data.get('clips', []))
    
    # N·∫øu c√≥ qu√° nhi·ªÅu clips, d√πng ph∆∞∆°ng ph√°p render t·ª´ng clip ra file t·∫°m
    if num_clips > MAX_CLIPS_DIRECT:
        print(f"\n‚ö†Ô∏è  Ph√°t hi·ªán {num_clips} clips (nhi·ªÅu h∆°n {MAX_CLIPS_DIRECT})")
        print("üìå S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p render t·ªëi ∆∞u (t·ª´ng clip -> concat)\n")
        return generate_ffmpeg_command_optimized(config_path)
    
    # S·ªë clips √≠t, d√πng ph∆∞∆°ng ph√°p c≈© (tr·ª±c ti·∫øp)
    print(f"\nüìå Render {num_clips} clips tr·ª±c ti·∫øp\n")

    input_map = {}
    inputs_list = []
    filter_chains = []
    concat_segments = []

    # ==========================================
    # T√çNH TO√ÅN TIMELINE T√çCH L≈®Y
    # ==========================================
    cumulative_time = 0.0
    clip_start_times = []

    for clip in json_data['clips']:
        clip_start_times.append(cumulative_time)

        # T√≠nh duration c·ªßa clip
        clip_duration = clip.get('duration')
        if not clip_duration:
            # T√¨m main video layer ƒë·ªÉ l·∫•y duration
            main_video = next((l for l in clip.get('layers', []) if l['type'] == 'video'), None)
            if main_video:
                cut_from = main_video.get('cutFrom', 0)
                cut_to = main_video.get('cutTo')
                clip_duration = cut_to - cut_from if cut_to else 0

        cumulative_time += clip_duration if clip_duration else 0

    # ==========================================
    # X·ª¨ L√ù VIDEO CLIPS
    # ==========================================
    for i, clip in enumerate(json_data['clips']):
        clip_duration = clip.get('duration')
        layers = clip.get('layers', [])
        clip_start_time = clip_start_times[i]

        out_v = f"v_clip_{i}_out"
        out_a = f"a_clip_{i}_out"
        current_v_pad = None
        has_audio = False

        main_video_layer = next((l for l in layers if l['type'] == 'video'), None)
        fill_color_layer = next((l for l in layers if l['type'] == 'fill-color'), None)

        # --- 1. PH√ÇN LO·∫†I LAYERS ---
        transition_layers = []
        logo_layers = []

        for layer in layers:
            if layer == main_video_layer or layer == fill_color_layer:
                continue

            if layer['type'] == 'video':
                # Transition video
                transition_layers.append(layer)
            elif layer['type'] == 'image-overlay':
                # Logo
                logo_layers.append(layer)

        # --- 2. T·∫†O LAYER N·ªÄN (BASE) ---
        if main_video_layer:
            path = main_video_layer['path']
            idx = get_input_index(path, input_map, inputs_list)
            cut_to = main_video_layer.get('cutTo')
            cut_from = main_video_layer.get('cutFrom', 0)
            segment_duration = cut_to - cut_from if cut_to else None

            trim_cmd = f"[{idx}:v]trim=start={cut_from}"
            if cut_to:
                trim_cmd += f":end={cut_to}"
            trim_cmd += f",setpts=PTS-STARTPTS[v_tmp_{i}_raw]"
            filter_chains.append(trim_cmd)

            if json_data.get('keepSourceAudio', True):
                atrim_cmd = f"[{idx}:a]atrim=start={cut_from}"
                if cut_to:
                    atrim_cmd += f":end={cut_to}"
                atrim_cmd += f",asetpts=PTS-STARTPTS[{out_a}]"
                filter_chains.append(atrim_cmd)
                has_audio = True

            if main_video_layer.get('resizeMode') == 'contain-blur':
                bg_chain = (f"[v_tmp_{i}_raw]split=2[bg_{i}][fg_{i}];"
                            f"[bg_{i}]scale={width}:{height}:force_original_aspect_ratio=increase,crop={width}:{height},boxblur=20:10[bg_blur_{i}];"
                            f"[fg_{i}]scale={width}:{height}:force_original_aspect_ratio=decrease[fg_scaled_{i}];"
                            f"[bg_blur_{i}][fg_scaled_{i}]overlay=(W-w)/2:(H-h)/2[v_base_{i}]")
                filter_chains.append(bg_chain)
                current_v_pad = f"[v_base_{i}]"
            else:
                scale_cmd = f"[v_tmp_{i}_raw]scale={width}:{height}:force_original_aspect_ratio=increase,crop={width}:{height}[v_base_{i}]"
                filter_chains.append(scale_cmd)
                current_v_pad = f"[v_base_{i}]"

        elif fill_color_layer:
            color = fill_color_layer.get('color', '#000000')
            dur = clip_duration if clip_duration else 0.1
            segment_duration = dur

            color_cmd = f"color=c={color}:s={width}x{height}:d={dur}[v_base_{i}]"
            filter_chains.append(color_cmd)
            current_v_pad = f"[v_base_{i}]"

            silence_cmd = f"anullsrc=cl=stereo:r=44100:d={dur}[{out_a}]"
            filter_chains.append(silence_cmd)
            has_audio = True

        # --- 3. OVERLAY LOGOS TR∆Ø·ªöC (logo ·ªü gi·ªØa, s·∫Ω b·ªã transition che khi c√≥ transition) ---
        for logo_idx, layer in enumerate(logo_layers):
            path = layer['path']
            idx = get_input_index(path, input_map, inputs_list)
            layer_pad = f"logo_{i}_{logo_idx}"

            # B·ªè loop filter, ch·ªâ scale logo PNG v·ªõi format t∆∞∆°ng th√≠ch
            cmd = f"[{idx}:v]scale={width}:{height}:force_original_aspect_ratio=decrease,format=yuva420p[{layer_pad}]"
            filter_chains.append(cmd)

            # Logo lu√¥n hi·ªÉn th·ªã, kh√¥ng c·∫ßn enable condition ph·ª©c t·∫°p
            # Transition s·∫Ω t·ª± ƒë·ªông che logo khi xu·∫•t hi·ªán
            next_pad = f"v_clip_{i}_logo_{logo_idx}"
            # B·ªè shortest=1, overlay t·ª± ƒë·ªông k√©o d√†i theo video base
            overlay_cmd = f"{current_v_pad}[{layer_pad}]overlay=(W-w)/2:(H-h)/2[{next_pad}]"
            filter_chains.append(overlay_cmd)
            current_v_pad = f"[{next_pad}]"

        # --- 4. OVERLAY TRANSITIONS SAU C√ôNG (ƒë√® l√™n logo, che logo khi c√≥ transition) ---
        overlay_idx = 0
        for layer in transition_layers:
            path = layer['path']
            idx = get_input_index(path, input_map, inputs_list)
            layer_pad = f"layer_{i}_{overlay_idx}"

            cut_from = layer.get('cutFrom', 0)
            cut_to = layer.get('cutTo')
            start_time = layer.get('start', 0)
            stop_time = layer.get('stop')

            trim_part = f"[{idx}:v]trim=start={cut_from}"
            if cut_to:
                trim_part += f":end={cut_to}"
            trim_part += f",setpts=PTS-STARTPTS[{layer_pad}_raw]"
            filter_chains.append(trim_part)

            scale_trans = f"[{layer_pad}_raw]scale={width}:{height}[{layer_pad}]"
            filter_chains.append(scale_trans)

            # Shift PTS ƒë·ªÉ transition xu·∫•t hi·ªán ƒë√∫ng th·ªùi ƒëi·ªÉm
            fps_fix = f"[{layer_pad}]setpts=PTS+{start_time}/TB[{layer_pad}_shifted]"
            filter_chains.append(fps_fix)

            # Enable transition video trong kho·∫£ng th·ªùi gian c·ªßa n√≥
            enable_expr = f"enable='between(t,{start_time},{stop_time})'"
            next_pad = f"v_clip_{i}_trans_{overlay_idx}"
            overlay_cmd = f"{current_v_pad}[{layer_pad}_shifted]overlay=0:0:{enable_expr}[{next_pad}]"
            filter_chains.append(overlay_cmd)
            current_v_pad = f"[{next_pad}]"
            overlay_idx += 1

        # --- 5. K·∫æT TH√öC CLIP ---
        if not has_audio:
            dur_str = f":d={segment_duration}" if segment_duration else ""
            silence_cmd = f"anullsrc=cl=stereo:r=44100{dur_str}[{out_a}]"
            filter_chains.append(silence_cmd)

        filter_chains.append(f"{current_v_pad}setsar=1[{out_v}]")
        concat_segments.append(f"[{out_v}]")
        concat_segments.append(f"[{out_a}]")

    # ==========================================
    # CONCAT & MIX
    # ==========================================
    n_clips = len(json_data['clips'])
    concat_cmd = "".join(concat_segments) + f"concat=n={n_clips}:v=1:a=1[main_video][main_audio_raw]"
    filter_chains.append(concat_cmd)

    audio_tracks = json_data.get('audioTracks', [])
    mix_inputs = ["[main_audio_raw]"]

    for k, track in enumerate(audio_tracks):
        path = track['path']
        idx = get_input_index(path, input_map, inputs_list)
        start = track.get('start', 0)
        cut_from = track.get('cutFrom', 0)
        cut_to = track.get('cutTo')
        mix_vol = track.get('mixVolume', 1)

        track_pad = f"track_{k}"
        delayed_pad = f"track_{k}_delayed"

        cmd = f"[{idx}:a]atrim=start={cut_from}"
        if cut_to:
            cmd += f":end={cut_to}"
        cmd += f",asetpts=PTS-STARTPTS,volume={mix_vol}[{track_pad}]"
        filter_chains.append(cmd)

        delay_ms = int(start * 1000)
        delay_cmd = f"[{track_pad}]adelay={delay_ms}|{delay_ms}[{delayed_pad}]"
        filter_chains.append(delay_cmd)
        mix_inputs.append(f"[{delayed_pad}]")

    if len(mix_inputs) > 1:
        mix_cmd = "".join(
            mix_inputs) + f"amix=inputs={len(mix_inputs)}:duration=first:dropout_transition=0[final_audio]"
        filter_chains.append(mix_cmd)
    else:
        filter_chains.append(f"[main_audio_raw]acopy[final_audio]")

    # ==========================================
    # EXECUTE
    # ==========================================
    cmd_args = [FFMPEG_EXEC, "-y"]
    for inp in inputs_list:
        cmd_args.extend(["-i", inp])

    cmd_args.extend(["-filter_complex", ";".join(filter_chains)])
    cmd_args.extend(["-map", "[main_video]", "-map", "[final_audio]"])
    cmd_args.extend([
        "-c:v", "h264_nvenc",
        "-preset", "p6",
        "-tune", "hq",
        "-rc", "vbr",
        "-cq", "23",
        "-b:v", "0",
        "-c:a", "aac",
        "-b:a", "192k",
        "-r", str(fps),
        out_path
    ])
    
    # In ra command ffmpeg ƒë·ªÉ debug
    print("\n" + "="*80)
    print("üé¨ FFMPEG COMMAND:")
    print("="*80)
    print(" ".join(shlex.quote(str(arg)) for arg in cmd_args))
    print("="*80 + "\n")
    
    try:
        subprocess.run(cmd_args, check=True)
        # T√¨m root window ƒë·ªÉ messagebox hi·ªÉn th·ªã ph√≠a tr√™n
        root = tk._default_root
        if root:
            for widget in root.winfo_children():
                if isinstance(widget, tk.Toplevel) and widget.winfo_exists():
                    widget.attributes('-topmost', True)
                    messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}", parent=widget)
                    widget.attributes('-topmost', False)
                    break
            else:
                messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}")
        else:
            messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}")
    except subprocess.CalledProcessError as e:
        # T√¨m root window ƒë·ªÉ messagebox hi·ªÉn th·ªã ph√≠a tr√™n
        root = tk._default_root
        if root:
            for widget in root.winfo_children():
                if isinstance(widget, tk.Toplevel) and widget.winfo_exists():
                    widget.attributes('-topmost', True)
                    messagebox.showerror("L·ªói render", f"FFmpeg render th·∫•t b·∫°i!\n\nM√£ l·ªói: {e.returncode}\n\nVui l√≤ng ki·ªÉm tra console ƒë·ªÉ xem chi ti·∫øt l·ªói.", parent=widget)
                    widget.attributes('-topmost', False)
                    break
            else:
                messagebox.showerror("L·ªói render", f"FFmpeg render th·∫•t b·∫°i!\n\nM√£ l·ªói: {e.returncode}\n\nVui l√≤ng ki·ªÉm tra console ƒë·ªÉ xem chi ti·∫øt l·ªói.")
        else:
            messagebox.showerror("L·ªói render", f"FFmpeg render th·∫•t b·∫°i!\n\nM√£ l·ªói: {e.returncode}\n\nVui l√≤ng ki·ªÉm tra console ƒë·ªÉ xem chi ti·∫øt l·ªói.")
        raise

def generate_ffmpeg_command_optimized(config_path):
    """
    Ph∆∞∆°ng ph√°p t·ªëi ∆∞u cho nhi·ªÅu clips: render t·ª´ng clip ra file t·∫°m, sau ƒë√≥ concat
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        json_data = json.load(f)
    
    width = json_data.get('width', 1920)
    height = json_data.get('height', 1080)
    fps = json_data.get('fps', 25)
    out_path = json_data.get('outPath', 'output.mp4')
    clips = json_data.get('clips', [])
    audio_tracks = json_data.get('audioTracks', [])
    
    # T·∫°o th∆∞ m·ª•c t·∫°m trong folder d·ª± √°n
    import uuid
    os.makedirs(TEMP_DIR, exist_ok=True)
    
    temp_dir = os.path.join(TEMP_DIR, f"ffmpeg_render_{uuid.uuid4().hex[:8]}")
    os.makedirs(temp_dir, exist_ok=True)
    print(f"üìÅ Th∆∞ m·ª•c t·∫°m: {temp_dir}\n")
    
    try:
        # B∆∞·ªõc 1: Render t·ª´ng clip ra file t·∫°m
        print("="*80)
        print(f"üé¨ B∆Ø·ªöC 1: RENDER {len(clips)} CLIPS RI√äNG L·∫∫")
        print("="*80)
        
        temp_clips = []
        for i, clip in enumerate(clips):
            temp_file, has_audio = render_clip_to_temp(clip, i, width, height, fps, temp_dir)
            temp_clips.append(temp_file)
        
        print(f"\n‚úÖ ƒê√£ render xong {len(temp_clips)} clips\n")
        
        # B∆∞·ªõc 2: T·∫°o concat list file
        print("="*80)
        print("üé¨ B∆Ø·ªöC 2: GH√âP C√ÅC CLIPS")
        print("="*80)
        
        concat_list_file = os.path.join(temp_dir, "concat_list.txt")
        with open(concat_list_file, 'w', encoding='utf-8') as f:
            for temp_file in temp_clips:
                # Escape single quotes trong path n·∫øu c√≥
                safe_path = temp_file.replace("'", "'\\''")
                f.write(f"file '{safe_path}'\n")
        
        print(f"üìù ƒê√£ t·∫°o concat list: {concat_list_file}")
        
        # B∆∞·ªõc 3: Concat video (ch∆∞a c√≥ audio tracks)
        temp_concat_video = os.path.join(temp_dir, "concat_video.mp4")
        
        concat_cmd = [
            FFMPEG_EXEC, "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", concat_list_file,
            "-c", "copy",
            temp_concat_video
        ]
        
        print("\nüìå Command concat:")
        print(" ".join(shlex.quote(str(arg)) for arg in concat_cmd))
        print()
        
        subprocess.run(concat_cmd, check=True, capture_output=True)
        print("‚úÖ ƒê√£ gh√©p video\n")
        
        # B∆∞·ªõc 4: Mix audio tracks n·∫øu c√≥
        if audio_tracks:
            print("="*80)
            print("üé¨ B∆Ø·ªöC 3: MIX AUDIO TRACKS")
            print("="*80)
            
            input_map = {}
            inputs_list = []
            filter_chains = []
            
            # Main audio t·ª´ video
            idx_main = get_input_index(temp_concat_video, input_map, inputs_list)
            mix_inputs = [f"[{idx_main}:a]"]
            
            # Nh√≥m audio tracks theo file path ƒë·ªÉ t·ªëi ∆∞u
            tracks_by_file = {}
            for track in audio_tracks:
                path = track['path']
                if path not in tracks_by_file:
                    tracks_by_file[path] = []
                tracks_by_file[path].append(track)
            
            # X·ª≠ l√Ω t·ª´ng file audio
            file_idx = 0
            for path, tracks in tracks_by_file.items():
                idx = get_input_index(path, input_map, inputs_list)
                
                # N·∫øu c√≥ nhi·ªÅu tracks t·ª´ c√πng 1 file, g·ªôp l·∫°i tr∆∞·ªõc
                if len(tracks) > 1:
                    # T·∫°o c√°c ph·∫ßn audio ri√™ng v√† g·ªôp ch√∫ng
                    track_parts = []
                    for k, track in enumerate(tracks):
                        start = track.get('start', 0)
                        cut_from = track.get('cutFrom', 0)
                        cut_to = track.get('cutTo')
                        mix_vol = track.get('mixVolume', 1)
                        
                        part_pad = f"file_{file_idx}_part_{k}"
                        
                        cmd = f"[{idx}:a]atrim=start={cut_from}"
                        if cut_to:
                            cmd += f":end={cut_to}"
                        cmd += f",asetpts=PTS-STARTPTS,volume={mix_vol},adelay={int(start * 1000)}|{int(start * 1000)}[{part_pad}]"
                        filter_chains.append(cmd)
                        track_parts.append(f"[{part_pad}]")
                    
                    # Mix t·∫•t c·∫£ parts t·ª´ c√πng file th√†nh 1 track
                    merged_pad = f"file_{file_idx}_merged"
                    merge_cmd = "".join(track_parts) + f"amix=inputs={len(track_parts)}:duration=first:dropout_transition=0[{merged_pad}]"
                    filter_chains.append(merge_cmd)
                    mix_inputs.append(f"[{merged_pad}]")
                else:
                    # Ch·ªâ 1 track t·ª´ file n√†y
                    track = tracks[0]
                    start = track.get('start', 0)
                    cut_from = track.get('cutFrom', 0)
                    cut_to = track.get('cutTo')
                    mix_vol = track.get('mixVolume', 1)
                    
                    track_pad = f"file_{file_idx}_single"
                    
                    cmd = f"[{idx}:a]atrim=start={cut_from}"
                    if cut_to:
                        cmd += f":end={cut_to}"
                    cmd += f",asetpts=PTS-STARTPTS,volume={mix_vol},adelay={int(start * 1000)}|{int(start * 1000)}[{track_pad}]"
                    filter_chains.append(cmd)
                    mix_inputs.append(f"[{track_pad}]")
                
                file_idx += 1
            
            # Mix t·∫•t c·∫£ inputs l·∫°i (b√¢y gi·ªù ch·ªâ c√≤n v√†i inputs thay v√¨ 58)
            mix_cmd = "".join(mix_inputs) + f"amix=inputs={len(mix_inputs)}:duration=first:dropout_transition=0[final_audio]"
            filter_chains.append(mix_cmd)
            
            # Final mix command
            final_cmd = [FFMPEG_EXEC, "-y"]
            for inp in inputs_list:
                final_cmd.extend(["-i", inp])
            
            final_cmd.extend(["-filter_complex", ";".join(filter_chains)])
            final_cmd.extend(["-map", f"{idx_main}:v", "-map", "[final_audio]"])
            final_cmd.extend([
                "-c:v", "copy",
                "-c:a", "aac",
                "-b:a", "192k",
                out_path
            ])
            
            print("\nüìå Command mix audio:")
            print(" ".join(shlex.quote(str(arg)) for arg in final_cmd))
            print()
            
            subprocess.run(final_cmd, check=True, capture_output=True)
            print("‚úÖ ƒê√£ mix audio\n")
        else:
            # Kh√¥ng c√≥ audio tracks, ch·ªâ c·∫ßn copy
            import shutil
            shutil.copy2(temp_concat_video, out_path)
        
        print("="*80)
        print("‚úÖ RENDER TH√ÄNH C√îNG!")
        print(f"üìÅ Output: {out_path}")
        print("="*80 + "\n")
        
        # Success message
        root = tk._default_root
        if root:
            for widget in root.winfo_children():
                if isinstance(widget, tk.Toplevel) and widget.winfo_exists():
                    widget.attributes('-topmost', True)
                    messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}", parent=widget)
                    widget.attributes('-topmost', False)
                    break
            else:
                messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}")
        else:
            messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}")
    
    except Exception as e:
        print(f"\n‚ùå L·ªñI: {e}\n")
        root = tk._default_root
        if root:
            for widget in root.winfo_children():
                if isinstance(widget, tk.Toplevel) and widget.winfo_exists():
                    widget.attributes('-topmost', True)
                    messagebox.showerror("L·ªói render", f"Render th·∫•t b·∫°i!\n\n{str(e)}", parent=widget)
                    widget.attributes('-topmost', False)
                    break
            else:
                messagebox.showerror("L·ªói render", f"Render th·∫•t b·∫°i!\n\n{str(e)}")
        else:
            messagebox.showerror("L·ªói render", f"Render th·∫•t b·∫°i!\n\n{str(e)}")
        raise
    finally:
        # D·ªçn d·∫πp file t·∫°m
        import shutil
        if os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
                print(f"üóëÔ∏è  ƒê√£ x√≥a th∆∞ m·ª•c t·∫°m: {temp_dir}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ x√≥a th∆∞ m·ª•c t·∫°m: {e}")

def run(cmd):
    print("‚öôÔ∏è Run:", " ".join(shlex.quote(c) for c in cmd))
    subprocess.run(cmd, check=True)


def build_and_render_from_config(video_config_path, config_dict):
    with open(video_config_path, "r", encoding="utf-8") as f:
        config = json.load(f)

    out_path = config["outPath"]
    width = 1920
    height = 1080
    fps = config_dict.get("fps")
    blur_amount = config_dict.get("blur") * 100
    keep_audio = config.get("keepSourceAudio", True)
    ffmpeg_opts = config.get("ffmpegOptions", {}).get("outputArgs", [])
    clips = config["clips"]

    transition_file = None
    if config.get("defaults") and config["defaults"].get("transition"):
        transition_file = config["defaults"]["transition"]

    # L·∫•y logo path t·ª´ config n·∫øu c√≥
    logo_path = None
    if clips and clips[0].get("layers"):
        overlay_layer = next((x for x in clips[0]["layers"] if x["type"] == "image-overlay"), None)
        if overlay_layer:
            logo_path = overlay_layer["path"]

    # === B∆Ø·ªöC 1: Render clips v·ªõi logo (tr·ª´ transition) ===
    clip_files = []
    for idx, clip_cfg in enumerate(clips):
        video_layer = next((x for x in clip_cfg["layers"] if x["type"] == "video"), None)
        if not video_layer:
            continue

        video_path = video_layer["path"]
        tmp_out = f"tmp_clip_{idx}_{uuid.uuid4().hex[:6]}.mp4"

        # ---- X√ÅC ƒê·ªäNH CLIP C√ì PH·∫¢I TRANSITION HAY KH√îNG ----
        is_transition_clip = "Transition.mov" in video_path

        # Input cho ffmpeg
        inputs = ["-i", video_path]
        filter_complex = []

        # ==== LOGIC OVERLAY LOGO ƒê√É ƒê∆Ø·ª¢C S·ª¨A ====
        if not is_transition_clip and logo_path and os.path.exists(logo_path):
            # C√≥ logo, KH√îNG ph·∫£i transition => overlay logo
            inputs += ["-i", logo_path]

            filter_complex.append("[0:v]split=2[bg][fg]")
            filter_complex.append(
                f"[bg]scale={width}:{height}:force_original_aspect_ratio=increase,"
                f"crop={width}:{height},"
                f"boxblur={blur_amount}:1[bg_blur]"
            )
            filter_complex.append(
                f"[fg]scale=-2:{height}:force_original_aspect_ratio=decrease[fg_scaled]"
            )
            filter_complex.append(
                f"[bg_blur][fg_scaled]overlay=(W-w)/2:(H-h)/2[composed]"
            )
            filter_complex.append(
                f"[composed][1:v]overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2[with_logo]"
            )
            filter_complex.append(
                f"[with_logo]fps={fps},setsar=1,format=yuv420p[outv]"
            )

        else:
            # L√† transition HO·∫∂C kh√¥ng c√≥ logo => kh√¥ng overlay logo
            filter_complex.append("[0:v]split=2[bg][fg]")
            filter_complex.append(
                f"[bg]scale={width}:{height}:force_original_aspect_ratio=increase,"
                f"crop={width}:{height},"
                f"boxblur={blur_amount}:1[bg_blur]"
            )
            filter_complex.append(
                f"[fg]scale=-2:{height}:force_original_aspect_ratio=decrease[fg_scaled]"
            )
            filter_complex.append(
                f"[bg_blur][fg_scaled]overlay=(W-w)/2:(H-h)/2[composed]"
            )
            filter_complex.append(
                f"[composed]fps={fps},setsar=1,format=yuv420p[outv]"
            )

        # Render video clip
        cmd = ["ffmpeg", "-y", "-hwaccel", "cuda"] + inputs
        cmd += ["-filter_complex", ";".join(filter_complex)]
        cmd += ["-map", "[outv]"]

        if keep_audio:
            cmd += ["-map", "0:a?"]

        cmd += ["-c:v", "libx264", "-preset", "medium", "-crf", "18"]
        if keep_audio:
            cmd += ["-c:a", "aac", "-b:a", "320k"]

        cmd += [tmp_out]
        run(cmd)
        clip_files.append(tmp_out)

    # === B∆Ø·ªöC 2: Render transitions (KH√îNG c√≥ logo) ===
    trans_files = []
    if transition_file:
        for idx in range(len(clip_files) - 1):
            trans_tmp = f"tmp_trans_{idx}_{uuid.uuid4().hex[:6]}.mp4"

            cmd = [
                "ffmpeg", "-y",
                "-i", transition_file,
                "-vf",
                f"scale={width}:{height}:force_original_aspect_ratio=increase,crop={width}:{height},fps={fps},setsar=1,format=yuv420p",
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "18",
                "-an",
                trans_tmp
            ]
            run(cmd)
            trans_files.append(trans_tmp)

    # === B∆Ø·ªöC 3: Concat video + transitions ===
    final_sequence = []
    for i, clip_file in enumerate(clip_files):
        final_sequence.append(clip_file)
        if i < len(trans_files):
            final_sequence.append(trans_files[i])

    # FFmpeg concat input
    inputs = []
    for f in final_sequence:
        inputs += ["-i", f]

    n = len(final_sequence)
    concat_filter = "".join([f"[{i}:v]" for i in range(n)])
    concat_filter += f"concat=n={n}:v=1:a=0[outv]"

    cmd = ["ffmpeg", "-y"] + inputs
    cmd += ["-filter_complex", concat_filter]
    cmd += ["-map", "[outv]"]

    # === Audio render ri√™ng ===
    if keep_audio:
        audio_inputs = []
        for cf in clip_files:
            audio_inputs += ["-i", cf]

        audio_filter = "".join([f"[{i}:a]" for i in range(len(clip_files))])
        audio_filter += f"concat=n={len(clip_files)}:v=0:a=1[outa]"

        temp_audio = f"temp_audio_{uuid.uuid4().hex[:6]}.aac"
        audio_cmd = ["ffmpeg", "-y"] + audio_inputs
        audio_cmd += ["-filter_complex", audio_filter]
        audio_cmd += ["-map", "[outa]", "-c:a", "aac", "-b:a", "320k", temp_audio]
        run(audio_cmd)

        temp_video_only = f"temp_video_{uuid.uuid4().hex[:6]}.mp4"
        cmd += ["-c:v", "h264_nvenc", "-preset", "p6", temp_video_only]
        run(cmd)

        final_cmd = [
            "ffmpeg", "-y",
            "-i", temp_video_only,
            "-i", temp_audio,
            "-c:v", "copy",
            "-c:a", "copy",
            out_path
        ]
        run(final_cmd)

        if os.path.exists(temp_audio):
            os.remove(temp_audio)
        if os.path.exists(temp_video_only):
            os.remove(temp_video_only)

    else:
        cmd += ["-c:v", "h264_nvenc", "-preset", "p6", out_path]
        run(cmd)

    # === X√ìA FILE T·∫†M ===
    for f in clip_files + trans_files:
        if os.path.exists(f):
            os.remove(f)

    print("‚úÖ DONE:", out_path)
    # T√¨m root window ƒë·ªÉ messagebox hi·ªÉn th·ªã ph√≠a tr√™n
    root = tk._default_root
    if root:
        for widget in root.winfo_children():
            if isinstance(widget, tk.Toplevel) and widget.winfo_exists():
                widget.attributes('-topmost', True)
                messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}", parent=widget)
                widget.attributes('-topmost', False)
                break
        else:
            messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}")
    else:
        messagebox.showinfo("Ho√†n th√†nh", f"Render video th√†nh c√¥ng!\n\nƒê∆∞·ªùng d·∫´n:\n{out_path}")
    return out_path
